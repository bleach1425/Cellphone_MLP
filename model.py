# -*- coding: utf-8 -*-
"""Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SdNqDQP0OHEnnNyz2lfBtOV7S_i4Kcbo
"""

import os
import glob
import pandas as pd
neg = pd.read_table("neg.txt",encoding="utf-8")
pos = pd.read_table("pos.txt",encoding="utf-8")
neg["tag"]=0
pos["tag"]=1
negd = pd.DataFrame(neg["content"].astype(str))
posd = pd.DataFrame(pos["content"].astype(str))
x_n = negd["content"]
p_p = posd["content"]
y_n = neg["tag"]
y_p = pos["tag"]
x = pd.concat([x_n,p_p])
y = pd.concat([y_n,y_p])
sum=0
for i in x:
  sum = sum+len(i)
a = sum/len(x)
print(a)

import jieba
jieba.set_dictionary("dict.txt")

def poemcut(s):
    s = " ".join(jieba.cut(s))
    return s
x_cut = x.apply(poemcut)
x_cut

from tensorflow.keras.preprocessing.text import Tokenizer
# 出現太少的詞, 你可以選擇不看, 只留出現次數最高的2000(num_words)
tok = Tokenizer(num_words=2000)
tok.fit_on_texts(x_cut)

# 文字轉成數字
x_seq = tok.texts_to_sequences(x_cut)
pd.DataFrame(x_seq)

# NLP沒辦法接受不同的字數,因此必須讓所有句子的字數一樣進去處理
from tensorflow.keras.preprocessing.sequence import pad_sequences
x_seq_pad = pad_sequences(x_seq, maxlen=64)
pd.DataFrame(x_seq_pad)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding
from tensorflow.keras.layers import Flatten , Dropout, Dense
layers=[
        #  2001*64 =128064
        Embedding(2001, 64, mask_zero=True, input_length=64),
        Flatten(),
        Dense(64,activation="relu"),
        Dropout(0.25),
        Dense(2,activation="softmax")
]
model = Sequential(layers)
model.summary()

from tensorflow.keras.losses import SparseCategoricalCrossentropy
model.compile(loss=SparseCategoricalCrossentropy(),
              optimizer="adam",
              metrics=["accuracy"]
)

import numpy as np
from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint
callbacks=[
           EarlyStopping(patience=3,restore_best_weights=True),
]

model.fit(x_seq_pad,
          np.array(y),
          batch_size = 200,
          epochs=4,
          validation_split=0.1,
          verbose=2,
          callbacks=callbacks)

model.evaluate(x_seq_pad, np.array(y))